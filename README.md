# ğŸš¢ Titanic Data Science: Duelo entre Deep Learning e Modelos ClÃ¡ssicos
**Por: Henrique Monteiro**

Este repositÃ³rio Ã© parte dos meus estudos contÃ­nuos em CiÃªncia de Dados e InteligÃªncia Artificial. O objetivo aqui foi aplicar modelos de Redes Neurais em um problema clÃ¡ssico de classificaÃ§Ã£o, unindo a base matemÃ¡tica aprendida na graduaÃ§Ã£o em FÃ­sica com ferramentas modernas de IA.

## ğŸš€ Sobre o Projeto
Neste experimento, utilizei uma arquitetura de rede neural do tipo **MLP (Multilayer Perceptron)** com camadas densas (16 e 8 neurÃ´nios). O foco principal deste estudo foi a etapa de **Feature Engineering** e o **Benchmarking** entre diferentes algoritmos para identificar a fronteira de decisÃ£o mais eficiente para o problema.

## ğŸ› ï¸ Stack Utilizada
* **Linguagem:** Python
* **Deep Learning:** TensorFlow & Keras
* **Machine Learning ClÃ¡ssico:** Scikit-Learn (Random Forest & SVM/SVC)
* **AnÃ¡lise e VisualizaÃ§Ã£o:** Pandas, NumPy, Seaborn e Matplotlib

## ğŸ§  O Duelo de Modelos
Para validar a eficÃ¡cia da Rede Neural, realizei um teste comparativo com modelos consolidados de Machine Learning. Os resultados finais de acurÃ¡cia foram:

| Modelo | AcurÃ¡cia (Teste) | CaracterÃ­stica |
| :--- | :--- | :--- |
| **SVM (SVC)** | **81.56%** | Vencedor: Melhor separaÃ§Ã£o geomÃ©trica dos dados padronizados. |
| **Rede Neural** | 81.01% | Alta capacidade de generalizaÃ§Ã£o com camadas ReLU. |
| **Random Forest** | 81.01% | Robustez excepcional para dados tabulares. |

## ğŸ“‰ O que foi explorado
* **PrÃ©-processamento:** Tratamento de dados ausentes e aplicaÃ§Ã£o de **StandardScaler** para garantir a convergÃªncia dos gradientes na Rede Neural.
* **AvaliaÃ§Ã£o de Performance:** Uso de **Matrizes de ConfusÃ£o** individuais para identificar a sensibilidade dos modelos em relaÃ§Ã£o a falsos positivos e negativos.
* **AnÃ¡lise de HiperparÃ¢metros:** Ajuste de Ã©pocas e tamanho de lote (batch size) para otimizaÃ§Ã£o do treinamento dos neurÃ´nios.

## ğŸ ConclusÃ£o TÃ©cnica
A anÃ¡lise comparativa revelou que, para este conjunto de dados, o **SVM (Support Vector Classifier)** apresentou a melhor performance. Este resultado reforÃ§a um princÃ­pio fundamental da CiÃªncia de Dados: a complexidade de um modelo (como uma Rede Neural) nem sempre supera algoritmos estatÃ­sticos clÃ¡ssicos em datasets de menor escala. 

A padronizaÃ§Ã£o dos dados foi o divisor de Ã¡guas, permitindo que o SVM encontrasse o hiperplano de separaÃ§Ã£o ideal. O projeto conclui que a escolha do modelo deve ser sempre pautada pela natureza dos dados e pela eficiÃªncia computacional.





