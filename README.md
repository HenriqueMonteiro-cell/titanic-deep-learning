# üö¢ Titanic Data Science: Duelo entre Deep Learning e Modelos Cl√°ssicos
**Por: Henrique Monteiro**

Este reposit√≥rio √© parte dos meus estudos cont√≠nuos em Ci√™ncia de Dados e Intelig√™ncia Artificial. O objetivo aqui foi aplicar modelos de Redes Neurais em um problema cl√°ssico de classifica√ß√£o, unindo a base matem√°tica aprendida na gradua√ß√£o em F√≠sica com ferramentas modernas de IA.

## üöÄ Sobre o Projeto
Neste experimento, utilizei uma arquitetura de rede neural do tipo **MLP (Multilayer Perceptron)** com camadas densas (16 e 8 neur√¥nios). O foco principal deste estudo foi a etapa de **Feature Engineering** e o **Benchmarking** entre diferentes algoritmos para identificar a fronteira de decis√£o mais eficiente para o problema.

## üõ†Ô∏è Stack Utilizada
* **Linguagem:** Python
* **Deep Learning:** TensorFlow & Keras
* **Machine Learning Cl√°ssico:** Scikit-Learn (Random Forest & SVM/SVC)
* **An√°lise e Visualiza√ß√£o:** Pandas, NumPy, Seaborn e Matplotlib

## üß† O Duelo de Modelos
Para validar a efic√°cia da Rede Neural, realizei um teste comparativo com modelos consolidados de Machine Learning. Os resultados finais de acur√°cia foram:

| Modelo | Acur√°cia (Teste) | Caracter√≠stica |
| :--- | :--- | :--- |
| **SVM (SVC)** | **81.56%** | Vencedor: Melhor separa√ß√£o geom√©trica dos dados padronizados. |
| **Rede Neural** | 81.01% | Alta capacidade de generaliza√ß√£o com camadas ReLU. |
| **Random Forest** | 81.01% | Robustez excepcional para dados tabulares. |

## üìâ O que foi explorado
* **Pr√©-processamento:** Tratamento de dados ausentes e aplica√ß√£o de **StandardScaler** para garantir a converg√™ncia dos gradientes na Rede Neural.
* **Avalia√ß√£o de Performance:** Uso de **Matrizes de Confus√£o** individuais para identificar a sensibilidade dos modelos em rela√ß√£o a falsos positivos e negativos.
* **An√°lise de Hiperpar√¢metros:** Ajuste de √©pocas e tamanho de lote (batch size) para otimiza√ß√£o do treinamento dos neur√¥nios.

## üèÅ Conclus√£o T√©cnica
A an√°lise comparativa revelou que, para este conjunto de dados, o **SVM (Support Vector Classifier)** apresentou a melhor performance. Este resultado refor√ßa um princ√≠pio fundamental da Ci√™ncia de Dados: a complexidade de um modelo (como uma Rede Neural) nem sempre supera algoritmos estat√≠sticos cl√°ssicos em datasets de menor escala. 

A padroniza√ß√£o dos dados foi o divisor de √°guas, permitindo que o SVM encontrasse o hiperplano de separa√ß√£o ideal. O projeto conclui que a escolha do modelo deve ser sempre pautada pela natureza dos dados e pela efici√™ncia computacional.

* Aprofundamento em **SQL** para manipula√ß√£o de bancos de dados estruturados.
* Estudo de arquiteturas de **IA Generativa** e t√©cnicas de RAG.
